% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/follow_up.R
\name{follow_up}
\alias{follow_up}
\title{Follow up a request}
\usage{
follow_up(
  prompt = listen(),
  context = NULL,
  conversation = last_conversation(),
  image = NULL,
  cache = getOption("ask.cache"),
  api_args = NULL,
  api_key = NULL
)
}
\arguments{
\item{prompt}{Your request, a string or a character vector that will be
concatenated to a string with line breaks as separators.}

\item{context}{An object of class "ask_context" usually built from a call
to \code{context()} or a \verb{context_*()} function. It is used to define a "system"
message that define the behavior, tone or focus of the assistant.}

\item{conversation}{A conversation, initiated by \code{ask()} or followed up by
\code{follow_up()}}

\item{image}{Path or URL to image to provide. Only considered for gpt models.}

\item{cache}{A path where to cache the outputs, or "ram" to store them
in RAM. useful to spare tokens and to have reproducible code.}

\item{api_key}{API key}

\item{model, api_args}{inherited from the last item
of \code{conversation} by default}
}
\value{
a conversation object
}
\description{
Continue a conversation, by default with the same parameters.
}
